{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8f02b",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2ebc518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:42:08.008307Z",
     "iopub.status.busy": "2025-09-08T17:42:08.007656Z",
     "iopub.status.idle": "2025-09-08T17:42:13.269139Z",
     "shell.execute_reply": "2025-09-08T17:42:13.268766Z",
     "shell.execute_reply.started": "2025-09-08T17:42:08.008250Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "import segment_anything\n",
    "import segmenteverygrain as seg\n",
    "import segmenteverygrain.interactions as si\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474ac20",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1bd2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:43:15.618113Z",
     "iopub.status.busy": "2025-09-08T17:43:15.617820Z",
     "iopub.status.idle": "2025-09-08T17:43:16.359902Z",
     "shell.execute_reply": "2025-09-08T17:43:16.359574Z",
     "shell.execute_reply.started": "2025-09-08T17:43:15.618098Z"
    }
   },
   "outputs": [],
   "source": "# Load UNET model\nunet = keras.saving.load_model(\n    \"../models/seg_model.keras\",\n    custom_objects={\"weighted_crossentropy\": seg.weighted_crossentropy},\n)\n\n# Download SAM model (only downloads it if it does not exist)\nimport os\nif not os.path.exists(\"../models/sam_vit_h_4b8939.pth\"):\n    import urllib.request\n    url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n    urllib.request.urlretrieve(url, \"../models/sam_vit_h_4b8939.pth\")\n\n# Load SAM\nfname = '../models/sam_vit_h_4b8939.pth'\nsam = segment_anything.sam_model_registry['default'](checkpoint=fname)\npredictor = segment_anything.SamPredictor(sam)"
  },
  {
   "cell_type": "markdown",
   "id": "a3c1dfc6",
   "metadata": {},
   "source": [
    "## Run segmentation\n",
    "\n",
    "Grains are supposed to be well defined in the image; e.g., if a grain consists of only a few pixels, it is unlikely to be detected.\n",
    "\n",
    "The segmentation can take a few minutes even for medium-sized images. Images with ~2000 pixels along their largest dimension are a good start and allow the user to get an idea about how well the segmentation works.\n",
    "\n",
    "Image used below is available from [here](https://github.com/zsylvester/segmenteverygrain/blob/main/examples/barton_creek/barton_creek_image.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b35f3",
   "metadata": {},
   "outputs": [],
   "source": "Image.MAX_IMAGE_PIXELS = None  # needed if working with very large images\n\nfname = \"../examples/barton_creek/barton_creek_image.jpg\"\n# fname = \"../examples/mair_et_al_L2_DJI_0382/mair_et_al_L2_DJI_0382_image_small.jpg\" # use this file if you want to try a larger image\n\nimage = si.load_image(fname) # load image\n\nall_grains, image_pred, all_coords = seg.predict_large_image(\n    fname, unet, sam, \n    min_area=400.0, \n    patch_size=2000, \n    overlap=200, \n    remove_edge_grains=False\n)\n\nfig, ax = plt.subplots()\nseg.plot_image_w_colorful_grains(image, all_grains, ax, cmap=\"tab20b\", \n        plot_image=True, im_alpha=1.0)"
  },
  {
   "cell_type": "markdown",
   "id": "9bb25eaa-c9c2-4e4f-b0b3-61dfbf8219b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:55:38.112664Z",
     "iopub.status.busy": "2025-09-08T17:55:38.112237Z",
     "iopub.status.idle": "2025-09-08T17:55:38.115860Z",
     "shell.execute_reply": "2025-09-08T17:55:38.115106Z",
     "shell.execute_reply.started": "2025-09-08T17:55:38.112630Z"
    }
   },
   "source": [
    "## Results and interactive editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9aaf7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring detected grains: 100%|██████████| 1253/1253 [00:01<00:00, 1048.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "grains = si.polygons_to_grains(all_grains, image=image)\n",
    "for g in tqdm(grains, desc='Measuring detected grains'):\n",
    "    g.measure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37715875",
   "metadata": {},
   "source": [
    "The editing interface itself is defined in `segmenteverygrain.interactions`.\n",
    "\n",
    "Navigation within the interface is described in the [matplotlib documentation](https://matplotlib.org/stable/users/explain/figure/interactive.html#interactive-navigation). Additional controls are:\n",
    "\n",
    "- `Left click` on existing grain: select/unselect \n",
    "- `Left click` in grain-free area: place foreground prompt for instant grain creation\n",
    "- `Alt` + `Left click` in grain-free area: place foreground prompt for multi-prompt grain creation\n",
    "- `Alt` + `Right click`: place background prompt for multi-prompt grain creation\n",
    "- `Shift` (hold): enable scale bar drawing\n",
    "- `Ctrl` (hold): temporarily hide selected grains\n",
    "- `Esc`: Remove all prompts and unselect all grains\n",
    "- `d`: Delete selected (highlighted) grains\n",
    "- `m`: Merge selected grains (must be touching)\n",
    "- `z`: Delete the most recently created grain\n",
    "\n",
    "Hints for these controls are shown in the figure title bar.\n",
    "\n",
    "Important parameters when calling `GrainPlot`:\n",
    "\n",
    "- `px_per_m`: The ratio of pixels to meters, if known. This will be overwritten if a scale bar is measured in the interface using middle click & drag.\n",
    "- `scale_m`: The length in meters of a reference object. Once the reference object is measured using left click & drag, size/area values will be converted to meters. The length of the line (shown as a red line) will be taken to represent `scale_m` meters.\n",
    "- `image_max_size` (y, x): Images larger than this in either dimension will be downscaled for display. Operations like grain detection will still be performed on the full image, but the display will not be able to zoom in at full quality. This is a performance optimization. Reduce this size for better performance, increase this size for better visual quality when zoomed.\n",
    "- `image_alpha`: Set this to a value lower than 1 to apply a fade effect to the background image.\n",
    "- `color_palette`: Matplotlib colormap to be used when plotting the grain masks.\n",
    "- `color_by`: Property to color grains by ('major_axis_length', 'minor_axis_length', 'area', 'perimeter', etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98c2bed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring and drawing grains: 100%|██████████| 1253/1253 [00:07<00:00, 166.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# You only need to run this cell if you want to interactively edit the segmentation results and/or if you want to draw a scale bar\n",
    "# If you want to draw a scale bar, you should change the 'scale_m' parameter before running this cell\n",
    "predictor.set_image(image)\n",
    "\n",
    "# Display interactive interface\n",
    "plot = si.GrainPlot(\n",
    "    grains,\n",
    "    image = image, \n",
    "    predictor = predictor,\n",
    "    blit = True,\n",
    "    color_palette = 'tab20b',\n",
    "    figsize = (12, 8),              # inches\n",
    "    scale_m = 0.1,             # meters; change this before launching 'GrainPlot'\n",
    "    color_by = None,\n",
    "    px_per_m = 1856.6             # px/m; alternative to 'scale_m'; will be overwritten if scale bar is drawn on image, using 'scale_m'\n",
    ")\n",
    "\n",
    "plot.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f241f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grains = plot.get_grains() # get data from the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea3719ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off interactive features\n",
    "plot.deactivate()\n",
    "\n",
    "# Draw the major and minor axes of each grain\n",
    "plot.draw_axes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "501a673a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve unit conversion factor if scale bar selected in image\n",
    "px_per_m = plot.px_per_m\n",
    "\n",
    "# hist = si.get_histogram(grains, px_per_m)\n",
    "summary = si.get_summary(grains, px_per_m)\n",
    "hist = seg.plot_histogram_of_axis_lengths(\n",
    "    summary['major_axis_length']*1000,\n",
    "    summary['minor_axis_length']*1000,\n",
    "    binsize=0.25,\n",
    "    # area=summary['area']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc3023-f325-4fa7-9ab6-e6c451f5d27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:56:49.579595Z",
     "iopub.status.busy": "2025-09-08T17:56:49.579362Z",
     "iopub.status.idle": "2025-09-08T17:56:49.583444Z",
     "shell.execute_reply": "2025-09-08T17:56:49.582881Z",
     "shell.execute_reply.started": "2025-09-08T17:56:49.579574Z"
    }
   },
   "source": [
    "The following results are then saved to the location specified in `out_fn`:\n",
    "- Grain shapes, for use elsewhere (geojson)\n",
    "- Summary data, presenting measurements for each detected grain (csv)\n",
    "- Summary histogram, representing major/minor axes of detected grains (jpg)\n",
    "- Mask representations of the detected grains, in both computer-readable (png, 0-1) and human-readable (jpg, 0-255) formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e20df0",
   "metadata": {},
   "outputs": [],
   "source": "# Save results\nout_fn = \"../examples/barton_creek/barton_creek_image\" # filename\n# Grain shapes\nsi.save_grains(out_fn + '_grains.geojson', grains)\n# Grain image\nplot.savefig(out_fn + '_grains.jpg')\n# Summary data\nsummary = si.save_summary(\n    out_fn + '_summary.csv', grains, px_per_m=plot.px_per_m)\n# Summary histogram\nsi.save_histogram(out_fn + '_summary.jpg', summary=summary)\n# Training mask\nsi.save_mask(out_fn + '_mask.png', grains, image, scale=False)\nsi.save_mask(out_fn + '_mask2.jpg', grains, image, scale=True)\nsummary.head()"
  },
  {
   "cell_type": "markdown",
   "id": "d25703e4-2a4e-4e98-aa49-ff9b816b2ec0",
   "metadata": {},
   "source": [
    "### Finetuning the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396f62c8-be0f-47fe-b660-2c55e2d51d42",
   "metadata": {},
   "outputs": [],
   "source": "# patchify images and masks\ninput_dir = \"../examples/unet_training/Masks_and_images/\"  # the input directory should contain files with 'image' and 'mask' in their filenames\npatch_dir = (\n    \"../examples/unet_training/\"  # a directory called \"Patches\" will be created here\n)\nimage_dir, mask_dir = seg.patchify_training_data(input_dir, patch_dir)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f98137-2dfd-4b88-8dc5-e4e79fa343ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation, and test datasets\n",
    "train_dataset, val_dataset, test_dataset = seg.create_train_val_test_data(\n",
    "    image_dir, mask_dir, augmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43650ad9-c2e5-4fc2-856f-4f39b8f1d9e3",
   "metadata": {},
   "outputs": [],
   "source": "# load base model weights and train the model with the new data\nmodel = seg.create_and_train_model(\n    train_dataset,\n    val_dataset,\n    test_dataset,\n    model_file=\"../models/seg_model.keras\",\n    epochs=100,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41375c1f-5f16-496f-b5e8-497626eb89dc",
   "metadata": {},
   "outputs": [],
   "source": "# save finetuned model as new model (this then can be loaded using \"model = load_model(\"new_model.keras\", custom_objects={'weighted_crossentropy': seg.weighted_crossentropy})\"\nmodel.save(\"../examples/unet_training/new_model.keras\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "segmenteverygrain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}